---
title: "ML-Agents : 에이전트 구성과 강화 학습 구현"
excerpt: "Agent 클래스에 대해서"
toc: true
toc_sticky: true
toc_label: "목차"
categories:
  - ML-Agents
tags:
  - [Unity]
date: 2021-03-24
breadcrumb: true
---


# 에이전트 구성과 강화 학습 구현

## 에이전트 구성

강화학습에 있어서 에이전트의 역할은 크게 3가지로 정의할 수 있다.

- 주변 환경을 관측
- 정책에 의한 행동
- 보상

이전에 만들어둔 학습 환경 구성중 에이전트에 대한 구현을 할 차례이다. 먼저 C# 스크립트를 생성하고 AgentObj로 이름은 변경한다.(그냥 Agent로 하려했으나 상속받은 클래스가 Agent라서 못했다.)

![Untitled.png](/assets/images/posts/2021-03-24/ml4/Untitled.png)

추가한 ML-Agents 패키지를 스크립트에서 사용하기 위해서 네임스페이스와 Agent 클래스를 상속받는다.

```csharp
using UnityEngine;
using Unity.MLAgents;

public class AgentObj : Agent
{
    
}
```

### Agent 클래스의 핵심 메소드

Agent 클래스에는 에이전트를 위한 메소드와 속성을 제공하며 Override해 사용할 수 있다.

```csharp
using UnityEngine;
using Unity.MLAgents;

public class MummyAgent : Agent
{
    //초기화 작업을 위해 한번 호출되는 메소드
    public override void Initialize() { }

    //에피소드(학습단위)가 시작할때마다 호출
    public override void OnEpisodeBegin() { }

    //환경 정보를 관측 및 수집해 정책 결정을 위해 브레인에 전달하는 메소드
    public override void CollectObservations(Unity.MLAgents.Sensors.VectorSensor sensor) { }

    //브레인(정책)으로 부터 전달 받은 행동을 실행하는 메소드
    public override void OnActionReceived(float[] vectorAction) { }

    //개발자(사용자)가 직접 명령을 내릴때 호출하는 메소드(주로 테스트용도 또는 모방학습에 사용)
    public override void Heuristic(float[] actionsOut) { }
}
```

### 관측 정보를 위한 변수 초기화

개발자는 어떠한 정보를 관측해야 더 효율적인가를 고민해야 한다. 에이전트는 다음 세가지 정보를 관측하기로 하고 이에 필요한 컴포넌트를 Initialize 메소드에서 할당.

- 에이전트의 속도
- 자신의 위치
- 타겟의 위치

```csharp
public class AgentObj : Agent
{
    private Transform tr;
    private Rigidbody rb;
    public Transform target; // 타겟의 위치

    public override void Initialize()
    {
        tr = GetComponent<Transform>(); // 에이전트 자신의 위치정보를 할당
        rb = GetComponent<Rigidbody>(); // 에이전트 자신의 물리정보를 할당
    }
}
```

### 학습 시작시 초기화 - OnEpisodeBegin

올바른 결과 또는 잘못된 결과에 도달하게 되면 학습을 종료하고 새로운 학습(에피소드)를 시작한다. OnEpisodeBegin 메소드는 학습이 시작할 때 마다 한번씩 호추로디는 메소드로 에이전트의 초기화 및 환경을 재설정 한다.

```csharp
//에피소드(학습단위)가 시작할때마다 호출
    public override void OnEpisodeBegin()
    {
        //물리력을 초기화
        rb.velocity = Vector3.zero;
        rb.angularVelocity = Vector3.zero;

        //에이젼트의 위치를 불규칙하게 변경
        tr.localPosition = new Vector3(Random.Range(-4.0f, 4.0f)
                                     , 0.55f
                                     , Random.Range(-4.0f, 4.0f));
        target.localPosition = new Vector3(Random.Range(-4.0f, 4.0f)
                                            , 0.55f
                                            , Random.Range(-4.0f, 4.0f));
    }
```

### 에이전트 초기화 확인

작성한 스크립트를 저장하고 Agent 오브젝트에 스크립트를 연결하여 씬을 실행할때마다 초기화가 진행되는지 확인한다.

Agent 오브젝트에 Rigidbody 컴포넌트를 추가하고 타겟을 설정해준다.

![Untitled%201.png](/assets/images/posts/2021-03-24/ml4/Untitled%201.png)

씬 재실행 테스트

![Untitled%202.png](/assets/images/posts/2021-03-24/ml4/Untitled%202.png)

![Untitled%203.png](/assets/images/posts/2021-03-24/ml4/Untitled%203.png)

두 오브젝트의 위치가 불규칙하게 변경되는 것으로 보아 OnEpisodeBegin 메소드가 정상적으로 실행된 것을 알 수 있다.

### 관측 정보 - CollectObservations

관측정보의 수집 및 전달은 CollectOvservations 메소드에서 VectorSensor.AddObservation 메소드를 사용한다. 넘겨주는 파라미터의 타입은 Vector 타입으로 유니티의 Vector와 다르게 다양한 유형의 데이터를 전달할 수 있다. 중요한 것은 넘겨주는 데이터의 크기로 아래 코드에서는 해당 메소드를 4번 호출했지만 각각 데이터의 크기는 3, 3, 1, 1로 총 8개의 데이터를 관측정보로 전달하는 것을 의미한다.

```csharp
//환경 정보를 관측 및 수집해 정책 결정을 위해 브레인에 전달하는 메소드
public override void CollectObservations(Unity.MLAgents.Sensors.VectorSensor sensor)
{
    sensor.AddObservation(target.localPosition);  //3 (x,y,z)
    sensor.AddObservation(tr.localPosition);        //3 (x,y,z)
    sensor.AddObservation(rb.velocity.x);           //1 (x)
    sensor.AddObservation(rb.velocity.z);           //1 (z)
}
```

관측 데이터의 크기인 8을 Behaviour Parameters 컴포넌트의 Vector Observation > Space Size 속성으로 설정한다.

![Untitled%204.png](/assets/images/posts/2021-03-24/ml4/Untitled%204.png)

### 이동처리 로직 - OnActionReceived

정책으로 부터 결정된 행동에 대해 에이전트가 수행할 동작은 OnActionReceived 메소드에서 처리한다. 정책으로 부터 전달되는 값은 연속적인 값과 이산 값으로 구분한다. 에이전트는 상하좌우 화살표 키 입력값으로 전진, 후진, 좌, 우로 이동 처리 한다.

```csharp
//브레인으로 부터 전달받은 액션(행위)를 실행하는 메소드
public override void OnActionReceived(float[] vectorAction)
{
    //데이터를 정규화
    float h = Mathf.Clamp(vectorAction[0], -1.0f, 1.0f);
    float v = Mathf.Clamp(vectorAction[1], -1.0f, 1.0f);
    Vector3 dir = (Vector3.forward * v) + (Vector3.right * h);
    rb.AddForce(dir.normalized * 50.0f);

    //지속적으로 이동을 이끌어내기 위한 마이너스 보상
    SetReward(-0.001f);
}
```

해당 프로젝트에서는 정책으로 부터 결정된 VectorAction 값이 연속적인 값이기 때문에 Behaviour Parameters의 Vector Action > Space Type 속성을 Continue로 지정한다. 또한 VectorAction의 종류로는 상하 값과 좌우 값 2세트이기에 Vector Action > Space Size 속성을 2로 설정한다.

![Untitled%205.png](/assets/images/posts/2021-03-24/ml4/Untitled%205.png)

### 테스트를 위한 키 입력 - Heuristic

학습을 훈력시키기 이전에 미리 테스트를 해보기 위해 사용자로부터 키보드 입력값을 받는 부분이 필요하다. 이 부분은 Heuristic 메소드에서 처리한다. 입력 값의 종류는 2가지로 정의, Input.GetAxis 메소드를 사용하기에 넘어오는 값의 범위는 -1.0f~1.0f이다. 즉, 연속적인 값을 넘겨준다.

```csharp
//개발자(사용자)가 직접 명령을 내릴때 호출하는 메소드(주로 테스트용도 또는 모방학습에 사용)
public override void Heuristic(float[] actionsOut)
{
    actionsOut[0] = Input.GetAxis("Horizontal"); //좌,우 화살표 키 //-1.0 ~ 0.0 ~ 1.0
    actionsOut[1] = Input.GetAxis("Vertical");   //상,하 화살표 키 //연속적인 값
    Debug.Log($"[0]={actionsOut[0]} [1]={actionsOut[1]}");
}
```

### Decision Requester 컴포넌트

Decision Requester는 에이전트가 어떻게 행동해야 할지 정책에 결정을 요청하는 컴포넌트이다. 정책은 에이전트가 주변 환경정보를 수집하고 관찰한 정보를 토대로 학습된 것을 의미한다. 이 컴포너트는 지속적으로 결정을 내려받아 행동해야 하는 학습 패턴의 경우 사용된다. 단, 턴제 게임과 같이 지속적인 결정을 필요로 하지 않을 때에는 추가하지 않는다.

![Untitled%206.png](/assets/images/posts/2021-03-24/ml4/Untitled%206.png)

### 충돌 및 보상 처리

에이전트가 타겟에 도달했을 때, +보상을 주고, Zone 영역에 충돌하면 -보상을 준다. 충돌 여부는 유니티의 OnCollisionEnter에서 처리한다.

보상을 주는 메소드는 SetReward, AddReward로 두 메소드의 차이는 다음과 같다.

- SetReward() : 이전 보상값을 지우고 현재의 보상값으로 대치. 누적된 보상값이 필요없을 경우 사용.
- AddReward() : 보상을 받고 바로 에피소드가 종료시키지 않고 계속해서 학습해야 하는 환경에서 사용.

```csharp
void OnCollisionEnter(Collision coll)
{
    if (coll.collider.CompareTag("Zone"))
    {
        //잘못된 행동일 때 마이너스 보상을 준다.
        SetReward(-1.0f);
        //학습을 종료시키는 메소드
        EndEpisode();
    }

    if (coll.collider.CompareTag("Target"))
    {
        //올바른 행동일 때 플러스 보상을 준다.
        SetReward(+1.0f);
        //학습을 종료시키는 메소드
        EndEpisode();
    }
}
```

충돌 처리시 시작적으로 성공 실패를 알기 위해서 바닥의 색상을 변경시켜보자. 다음과 같은 이름의 Material을 2개 생성해 다른 색상으로 지정한다.

- GoodMt : 노란색
- BadMt : 빨간색

바닥의 색상을 변경하기 위해 AgentObj의 스크립트를 변경.

```csharp
public class AgentObj : Agent
{
    private Transform tr;
    private Rigidbody rb;
    public Transform target; // 타겟의 위치

    // 바닥 색상 변경을 위한 변수들
    public Renderer floorRd;
    private Material originMt;
    public Material goodMt;
    public Material badMt;

    public override void Initialize()
    {
        tr = GetComponent<Transform>(); // 에이전트 자신의 위치정보를 참조
        rb = GetComponent<Rigidbody>(); // 에이전트 자신의 물리정보를 참조
        originMt = floorRd.material; // 기존의 바닥 Material을 저장.
    }
```

추가된 만큼의 public 변수들을 알맞게 할당해준다.

![Untitled%207.png](/assets/images/posts/2021-03-24/ml4/Untitled%207.png)

OnCollisionEnter 함수에서 충돌이 일어나면 바닥 색상이 바뀌도록 코드를 수정해준다.

```csharp
void OnCollisionEnter(Collision coll)
    {
        if (coll.collider.CompareTag("Zone"))
        {
            floorRd.material = badMt;

            //잘못된 행동일 때 마이너스 보상을 준다.
            SetReward(-1.0f);
            //학습을 종료시키는 메소드
            EndEpisode();
        }

        if (coll.collider.CompareTag("Target"))
        {
            floorRd.material = goodMt;

            //올바른 행동일 때 플러스 보상을 준다.
            SetReward(+1.0f);
            //학습을 종료시키는 메소드
            EndEpisode();
        }
    }
```

에피소드가 재시작되면 바닥의 색상을 원래대로 되돌리도록 코루틴을 사용한다.

```csharp
//에피소드(학습단위)가 시작할때마다 호출
    public override void OnEpisodeBegin()
    {
        //물리력을 초기화
        rb.velocity = Vector3.zero;
        rb.angularVelocity = Vector3.zero;

        //에이젼트의 위치를 불규칙하게 변경
        tr.localPosition = new Vector3(Random.Range(-4.0f, 4.0f)
                                     , 0.55f
                                     , Random.Range(-4.0f, 4.0f));
        target.localPosition = new Vector3(Random.Range(-4.0f, 4.0f)
                                            , 0.55f
                                            , Random.Range(-4.0f, 4.0f));

        StartCoroutine(RevertMaterial()); // 바닥 색상 초기화
    }

    IEnumerator RevertMaterial() // 바닥 생상 초기화 코루틴
    {
        yield return new WaitForSeconds(0.2f);
        floorRd.material = originMt;
    }
```

## 학습 효율을 위한 환경 복제

지금까지 생성한 stage를 프리팹으로 전환시킨 후 씬에 여러개 복사한다.

![Untitled%208.png](/assets/images/posts/2021-03-24/ml4/Untitled%208.png)

방향키를 사용하여 Target 또는 Zone에 충돌할때 바닥 색상이 변경되고 돌아오는지 확인해보자.

![Untitled%209.png](/assets/images/posts/2021-03-24/ml4/Untitled%209.png)

강화학습을 위한 환경 구축이 완성되었다. 다음은 학습을 시켜 결과를 얻어보는 작업을 하겠다.